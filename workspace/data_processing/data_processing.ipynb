{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b5b5be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import logging\n",
    "import psycopg2\n",
    "from openai import OpenAI\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from psycopg2.extras import Json\n",
    "from typing import Dict, List, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3e712c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcess:\n",
    "    \"\"\"\n",
    "    A class to manage support tickets with vector embeddings and image storage.\n",
    "\n",
    "    This system handles:\n",
    "    - Database operations with PostgreSQL and pgvector\n",
    "    - S3 storage for ticket-related images\n",
    "    - OpenAI embeddings for semantic search\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config_path: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        Initialize the DataProcess with configuration.\n",
    "\n",
    "        Args:\n",
    "            config_path: Optional path to a JSON configuration file\n",
    "        \"\"\"\n",
    "        # Set up logging\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
    "        )\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "        # Load environment variables\n",
    "        load_dotenv()\n",
    "\n",
    "        # Load configuration\n",
    "        self.config = self._load_config(config_path)\n",
    "\n",
    "        # Initialize clients\n",
    "        self.openai_client = self._init_openai_client()\n",
    "        self.s3_client = self._init_s3_client()\n",
    "        self.has_vector_support = False\n",
    "\n",
    "        # Store tickets data\n",
    "        self.support_tickets = []\n",
    "\n",
    "    def _load_config(self, config_path: Optional[str]) -> Dict:\n",
    "        \"\"\"\n",
    "        Load configuration from a file or use environment variables.\n",
    "\n",
    "        Args:\n",
    "            config_path: Path to a JSON configuration file\n",
    "\n",
    "        Returns:\n",
    "            Dict containing configuration settings\n",
    "        \"\"\"\n",
    "        config = {\n",
    "            \"openai\": {\"api_key\": os.getenv(\"OPENAI_API_KEY\")},\n",
    "            \"database\": {\n",
    "                \"host\": \"localhost\",\n",
    "                \"port\": \"5435\",\n",
    "                \"name\": \"postgres\",\n",
    "                \"user\": \"postgres\",\n",
    "                \"password\": \"postgres\",\n",
    "                \"table_name\": \"vector_table\",\n",
    "            },\n",
    "            \"s3\": {\n",
    "                \"bucket_name\": \"xyz-support-images\",\n",
    "                \"access_key_id\": \"test\",\n",
    "                \"secret_access_key\": \"test\",\n",
    "                \"region\": \"us-east-1\",\n",
    "                \"endpoint_url\": \"http://localhost:4566\",\n",
    "            },\n",
    "            \"data\": {\"tickets_file\": \"./data/vector_ticket_data.json\"},\n",
    "        }\n",
    "\n",
    "        # Override with file config if provided\n",
    "        if config_path:\n",
    "            try:\n",
    "                with open(config_path, \"r\") as f:\n",
    "                    file_config = json.load(f)\n",
    "                    # Deep merge the configurations\n",
    "                    self._merge_configs(config, file_config)\n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Error loading config file: {e}\")\n",
    "\n",
    "        return config\n",
    "\n",
    "    def _merge_configs(self, base: Dict, override: Dict) -> None:\n",
    "        \"\"\"\n",
    "        Recursively merge two configuration dictionaries.\n",
    "\n",
    "        Args:\n",
    "            base: Base configuration dict that will be updated\n",
    "            override: Dict with values to override in base\n",
    "        \"\"\"\n",
    "        for key, value in override.items():\n",
    "            if isinstance(value, dict) and key in base and isinstance(base[key], dict):\n",
    "                self._merge_configs(base[key], value)\n",
    "            else:\n",
    "                base[key] = value\n",
    "\n",
    "    def _init_openai_client(self) -> OpenAI:\n",
    "        \"\"\"\n",
    "        Initialize the OpenAI client.\n",
    "\n",
    "        Returns:\n",
    "            OpenAI client instance\n",
    "        \"\"\"\n",
    "        api_key = self.config[\"openai\"][\"api_key\"]\n",
    "        if not api_key:\n",
    "            self.logger.warning(\"OpenAI API key not found. Embeddings will not work.\")\n",
    "\n",
    "        return OpenAI(api_key=api_key)\n",
    "\n",
    "    def _init_s3_client(self) -> boto3.client:\n",
    "        \"\"\"\n",
    "        Initialize the S3 client.\n",
    "\n",
    "        Returns:\n",
    "            boto3 S3 client\n",
    "        \"\"\"\n",
    "        return boto3.client(\n",
    "            \"s3\",\n",
    "            aws_access_key_id=self.config[\"s3\"][\"access_key_id\"],\n",
    "            aws_secret_access_key=self.config[\"s3\"][\"secret_access_key\"],\n",
    "            region_name=self.config[\"s3\"][\"region\"],\n",
    "            endpoint_url=self.config[\"s3\"][\"endpoint_url\"],\n",
    "        )\n",
    "\n",
    "    def _get_db_connection(self) -> psycopg2.extensions.connection:\n",
    "        \"\"\"\n",
    "        Create a database connection.\n",
    "\n",
    "        Returns:\n",
    "            PostgreSQL connection object\n",
    "\n",
    "        Raises:\n",
    "            Exception: If connection fails\n",
    "        \"\"\"\n",
    "        db_config = self.config[\"database\"]\n",
    "        return psycopg2.connect(\n",
    "            host=db_config[\"host\"],\n",
    "            port=db_config[\"port\"],\n",
    "            dbname=db_config[\"name\"],\n",
    "            user=db_config[\"user\"],\n",
    "            password=db_config[\"password\"],\n",
    "        )\n",
    "\n",
    "    def load_tickets(self, file_path: Optional[str] = None) -> None:\n",
    "        \"\"\"\n",
    "        Load support tickets data from a JSON file.\n",
    "\n",
    "        Args:\n",
    "            file_path: Path to JSON file containing ticket data\n",
    "        \"\"\"\n",
    "        path = file_path or self.config[\"data\"][\"tickets_file\"]\n",
    "        try:\n",
    "            with open(path, \"r\") as f:\n",
    "                self.support_tickets = json.load(f)\n",
    "            self.logger.info(f\"Loaded {len(self.support_tickets)} tickets from {path}\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error loading tickets from {path}: {e}\")\n",
    "            self.support_tickets = []\n",
    "\n",
    "    def setup_database(self) -> bool:\n",
    "        \"\"\"\n",
    "        Set up the database tables and extensions.\n",
    "\n",
    "        Returns:\n",
    "            bool: True if pgvector support is available, False otherwise\n",
    "        \"\"\"\n",
    "        conn = None\n",
    "        try:\n",
    "            conn = self._get_db_connection()\n",
    "            cur = conn.cursor()\n",
    "\n",
    "            # Try creating the vector extension\n",
    "            try:\n",
    "                cur.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n",
    "                conn.commit()\n",
    "                self.logger.info(\"pgvector extension enabled successfully\")\n",
    "\n",
    "                # Create table with vector support\n",
    "                self._create_table_with_vector(cur, conn)\n",
    "                self.has_vector_support = True\n",
    "                return True\n",
    "\n",
    "            except Exception as e:\n",
    "                conn.rollback()\n",
    "                self.logger.warning(f\"Could not create pgvector extension: {e}\")\n",
    "                self.logger.info(\"Creating table without vector column\")\n",
    "\n",
    "                # Create table without vector support as fallback\n",
    "                self._create_table_without_vector(cur, conn)\n",
    "                self.has_vector_support = False\n",
    "                return False\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Database setup error: {e}\")\n",
    "            if conn:\n",
    "                conn.rollback()\n",
    "            return False\n",
    "        finally:\n",
    "            if conn:\n",
    "                conn.close()\n",
    "\n",
    "    def _create_table_with_vector(self, cursor, connection) -> None:\n",
    "        \"\"\"\n",
    "        Create database table with vector column.\n",
    "\n",
    "        Args:\n",
    "            cursor: Database cursor\n",
    "            connection: Database connection\n",
    "        \"\"\"\n",
    "        table_name = self.config[\"database\"][\"table_name\"]\n",
    "        cursor.execute(\n",
    "            f\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "                id SERIAL PRIMARY KEY,\n",
    "                ticket_id VARCHAR(20) UNIQUE NOT NULL,\n",
    "                subject TEXT NOT NULL,\n",
    "                description TEXT NOT NULL,\n",
    "                customer JSONB NOT NULL,\n",
    "                metadata JSONB NOT NULL,\n",
    "                resolution JSONB,\n",
    "                embedding vector(1536),\n",
    "                created_at TIMESTAMP NOT NULL DEFAULT NOW()\n",
    "            );\n",
    "            \"\"\"\n",
    "        )\n",
    "        connection.commit()\n",
    "        self.logger.info(\"Table with vector column created successfully\")\n",
    "\n",
    "    def _create_table_without_vector(self, cursor, connection) -> None:\n",
    "        \"\"\"\n",
    "        Create database table without vector column.\n",
    "\n",
    "        Args:\n",
    "            cursor: Database cursor\n",
    "            connection: Database connection\n",
    "        \"\"\"\n",
    "        table_name = self.config[\"database\"][\"table_name\"]\n",
    "        cursor.execute(\n",
    "            f\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "                id SERIAL PRIMARY KEY,\n",
    "                ticket_id VARCHAR(20) UNIQUE NOT NULL,\n",
    "                subject TEXT NOT NULL,\n",
    "                description TEXT NOT NULL,\n",
    "                customer JSONB NOT NULL,\n",
    "                metadata JSONB NOT NULL,\n",
    "                resolution JSONB,\n",
    "                created_at TIMESTAMP NOT NULL DEFAULT NOW()\n",
    "            );\n",
    "            \"\"\"\n",
    "        )\n",
    "        connection.commit()\n",
    "        self.logger.info(\"Table without vector column created successfully\")\n",
    "\n",
    "    def setup_s3_bucket(self) -> None:\n",
    "        \"\"\"Create the S3 bucket if it doesn't exist.\"\"\"\n",
    "        bucket_name = self.config[\"s3\"][\"bucket_name\"]\n",
    "        try:\n",
    "            # Check if bucket exists\n",
    "            self.s3_client.head_bucket(Bucket=bucket_name)\n",
    "            self.logger.info(f\"Bucket {bucket_name} already exists\")\n",
    "        except Exception:\n",
    "            # Create the bucket\n",
    "            try:\n",
    "                self.s3_client.create_bucket(Bucket=bucket_name)\n",
    "                self.logger.info(f\"Created S3 bucket: {bucket_name}\")\n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Error creating S3 bucket: {e}\")\n",
    "\n",
    "    def upload_images(self) -> None:\n",
    "        \"\"\"Upload images from the data folder to S3.\"\"\"\n",
    "        self.setup_s3_bucket()\n",
    "\n",
    "        # Gather all image data from tickets\n",
    "        image_data = []\n",
    "        for ticket in self.support_tickets:\n",
    "            if \"metadata\" in ticket and \"images\" in ticket[\"metadata\"]:\n",
    "                ticket_id = ticket[\"ticket_id\"]\n",
    "                for image in ticket[\"metadata\"][\"images\"]:\n",
    "                    image_data.append(\n",
    "                        {\n",
    "                            \"s3_key\": image[\"s3_key\"],\n",
    "                            \"description\": image[\"description\"],\n",
    "                            \"ticket_id\": ticket_id,\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "        # Upload each image\n",
    "        for img_info in image_data:\n",
    "            self._upload_single_image(img_info)\n",
    "\n",
    "    def _upload_single_image(self, img_info: Dict) -> None:\n",
    "        \"\"\"\n",
    "        Upload a single image to S3.\n",
    "\n",
    "        Args:\n",
    "            img_info: Dict containing image information\n",
    "        \"\"\"\n",
    "        bucket_name = self.config[\"s3\"][\"bucket_name\"]\n",
    "        try:\n",
    "            # Construct the local file path\n",
    "            local_file_path = os.path.join(\"data\", img_info[\"s3_key\"])\n",
    "\n",
    "            # Check if the file exists\n",
    "            if not os.path.exists(local_file_path):\n",
    "                self.logger.warning(f\"Local image {local_file_path} not found\")\n",
    "                return\n",
    "\n",
    "            # Read the file content\n",
    "            with open(local_file_path, \"rb\") as file:\n",
    "                file_content = file.read()\n",
    "\n",
    "            # Upload to S3\n",
    "            self.s3_client.put_object(\n",
    "                Bucket=bucket_name,\n",
    "                Key=img_info[\"s3_key\"],\n",
    "                Body=file_content,\n",
    "                ContentType=\"image/png\",\n",
    "            )\n",
    "            self.logger.info(\n",
    "                f\"Uploaded image to s3://{bucket_name}/{img_info['s3_key']}\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error uploading image {img_info['s3_key']}: {e}\")\n",
    "\n",
    "    def generate_embedding(self, text: str) -> Optional[List[float]]:\n",
    "        \"\"\"\n",
    "        Generate embedding vector using OpenAI's embedding model.\n",
    "\n",
    "        Args:\n",
    "            text: Text to generate embedding for\n",
    "\n",
    "        Returns:\n",
    "            List of embedding values or None if generation fails\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = self.openai_client.embeddings.create(\n",
    "                model=\"text-embedding-ada-002\", input=text\n",
    "            )\n",
    "            embedding = response.data[0].embedding\n",
    "            return embedding\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error generating embedding: {e}\")\n",
    "            return None\n",
    "\n",
    "    def verify_s3_images(self, ticket: Dict) -> Dict:\n",
    "        \"\"\"\n",
    "        Verify that images exist in S3 bucket and add presigned URLs.\n",
    "\n",
    "        Args:\n",
    "            ticket: Ticket data dictionary\n",
    "\n",
    "        Returns:\n",
    "            Updated ticket dictionary with image verification info\n",
    "        \"\"\"\n",
    "        bucket_name = self.config[\"s3\"][\"bucket_name\"]\n",
    "\n",
    "        if \"metadata\" in ticket and \"images\" in ticket[\"metadata\"]:\n",
    "            for image in ticket[\"metadata\"][\"images\"]:\n",
    "                s3_key = image[\"s3_key\"]\n",
    "                try:\n",
    "                    # Check if the image exists in S3\n",
    "                    self.s3_client.head_object(Bucket=bucket_name, Key=s3_key)\n",
    "\n",
    "                    # Add a presigned URL\n",
    "                    presigned_url = self.s3_client.generate_presigned_url(\n",
    "                        \"get_object\", Params={\"Bucket\": bucket_name, \"Key\": s3_key}\n",
    "                    )\n",
    "                    image[\"presigned_url\"] = presigned_url\n",
    "                    image[\"exists\"] = True\n",
    "\n",
    "                except Exception as e:\n",
    "                    self.logger.warning(f\"Image {s3_key} not found in S3: {e}\")\n",
    "                    image[\"exists\"] = False\n",
    "\n",
    "        return ticket\n",
    "\n",
    "    def insert_ticket(self, ticket: Dict) -> bool:\n",
    "        \"\"\"\n",
    "        Insert a support ticket with its embedding into the database.\n",
    "\n",
    "        Args:\n",
    "            ticket: Ticket data dictionary\n",
    "\n",
    "        Returns:\n",
    "            bool: True if insertion succeeded, False otherwise\n",
    "        \"\"\"\n",
    "        conn = None\n",
    "        try:\n",
    "            # Verify S3 images\n",
    "            ticket = self.verify_s3_images(ticket)\n",
    "\n",
    "            # Connect to PostgreSQL\n",
    "            conn = self._get_db_connection()\n",
    "            cur = conn.cursor()\n",
    "\n",
    "            # Generate embedding if vector support is available\n",
    "            embedding = None\n",
    "            if self.has_vector_support:\n",
    "                # Generate text for embedding\n",
    "                embedding_text = f\"{ticket['subject']} {ticket['description']}\"\n",
    "                if \"resolution\" in ticket and \"solution\" in ticket[\"resolution\"]:\n",
    "                    embedding_text += f\" {ticket['resolution']['solution']}\"\n",
    "\n",
    "                # Generate embedding\n",
    "                embedding = self.generate_embedding(embedding_text)\n",
    "\n",
    "            table_name = self.config[\"database\"][\"table_name\"]\n",
    "\n",
    "            if self.has_vector_support and embedding:\n",
    "                self._insert_with_vector(cur, table_name, ticket, embedding)\n",
    "            else:\n",
    "                self._insert_without_vector(cur, table_name, ticket)\n",
    "\n",
    "            # Commit the transaction\n",
    "            conn.commit()\n",
    "            self.logger.info(f\"Ticket {ticket['ticket_id']} inserted successfully\")\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error inserting ticket {ticket['ticket_id']}: {e}\")\n",
    "            if conn:\n",
    "                conn.rollback()\n",
    "            return False\n",
    "        finally:\n",
    "            if conn:\n",
    "                conn.close()\n",
    "\n",
    "    def _insert_with_vector(\n",
    "        self, cursor, table_name: str, ticket: Dict, embedding: List[float]\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Insert ticket with vector embedding.\n",
    "\n",
    "        Args:\n",
    "            cursor: Database cursor\n",
    "            table_name: Name of the database table\n",
    "            ticket: Ticket data dictionary\n",
    "            embedding: List of embedding values\n",
    "        \"\"\"\n",
    "        cursor.execute(\n",
    "            f\"\"\"\n",
    "            INSERT INTO {table_name} \n",
    "            (ticket_id, subject, description, customer, metadata, resolution, embedding, created_at)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s::vector, %s)\n",
    "            ON CONFLICT (ticket_id) \n",
    "            DO UPDATE SET\n",
    "                subject = EXCLUDED.subject,\n",
    "                description = EXCLUDED.description,\n",
    "                customer = EXCLUDED.customer,\n",
    "                metadata = EXCLUDED.metadata,\n",
    "                resolution = EXCLUDED.resolution,\n",
    "                embedding = EXCLUDED.embedding,\n",
    "                created_at = EXCLUDED.created_at\n",
    "            \"\"\",\n",
    "            (\n",
    "                ticket[\"ticket_id\"],\n",
    "                ticket[\"subject\"],\n",
    "                ticket[\"description\"],\n",
    "                Json(ticket[\"customer\"]),\n",
    "                Json(ticket[\"metadata\"]),\n",
    "                Json(ticket[\"resolution\"]) if \"resolution\" in ticket else None,\n",
    "                str(embedding),  # Convert list to string for casting\n",
    "                datetime.now(),\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def _insert_without_vector(self, cursor, table_name: str, ticket: Dict) -> None:\n",
    "        \"\"\"\n",
    "        Insert ticket without vector embedding.\n",
    "\n",
    "        Args:\n",
    "            cursor: Database cursor\n",
    "            table_name: Name of the database table\n",
    "            ticket: Ticket data dictionary\n",
    "        \"\"\"\n",
    "        cursor.execute(\n",
    "            f\"\"\"\n",
    "            INSERT INTO {table_name} \n",
    "            (ticket_id, subject, description, customer, metadata, resolution, created_at)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "            ON CONFLICT (ticket_id) \n",
    "            DO UPDATE SET\n",
    "                subject = EXCLUDED.subject,\n",
    "                description = EXCLUDED.description,\n",
    "                customer = EXCLUDED.customer,\n",
    "                metadata = EXCLUDED.metadata,\n",
    "                resolution = EXCLUDED.resolution,\n",
    "                created_at = EXCLUDED.created_at\n",
    "            \"\"\",\n",
    "            (\n",
    "                ticket[\"ticket_id\"],\n",
    "                ticket[\"subject\"],\n",
    "                ticket[\"description\"],\n",
    "                Json(ticket[\"customer\"]),\n",
    "                Json(ticket[\"metadata\"]),\n",
    "                Json(ticket[\"resolution\"]) if \"resolution\" in ticket else None,\n",
    "                datetime.now(),\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def test_connections(self) -> None:\n",
    "        \"\"\"Test database and S3 connections and log the results.\"\"\"\n",
    "        self.logger.info(\"Testing Database Connection\")\n",
    "        try:\n",
    "            conn = self._get_db_connection()\n",
    "            cur = conn.cursor()\n",
    "            cur.execute(\"SELECT version();\")\n",
    "            version = cur.fetchone()\n",
    "            self.logger.info(f\"Connected to PostgreSQL: {version[0]}\")\n",
    "\n",
    "            # Check pgvector extension\n",
    "            cur.execute(\n",
    "                \"SELECT name, installed_version FROM pg_available_extensions WHERE name = 'vector';\"\n",
    "            )\n",
    "            ext = cur.fetchone()\n",
    "            if ext:\n",
    "                self.logger.info(f\"pgvector is available: {ext}\")\n",
    "\n",
    "                # Check if installed\n",
    "                cur.execute(\n",
    "                    \"SELECT extname, extversion FROM pg_extension WHERE extname = 'vector';\"\n",
    "                )\n",
    "                installed = cur.fetchone()\n",
    "                if installed:\n",
    "                    self.logger.info(f\"pgvector is installed: {installed}\")\n",
    "                else:\n",
    "                    self.logger.info(\"pgvector is available but not installed yet\")\n",
    "            else:\n",
    "                self.logger.info(\"pgvector extension is not available\")\n",
    "\n",
    "            conn.close()\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"PostgreSQL connection error: {e}\")\n",
    "\n",
    "        self.logger.info(\"Testing S3 Connection\")\n",
    "        try:\n",
    "            response = self.s3_client.list_buckets()\n",
    "            self.logger.info(\n",
    "                f\"Connected to S3, found {len(response['Buckets'])} buckets\"\n",
    "            )\n",
    "            for bucket in response[\"Buckets\"]:\n",
    "                self.logger.info(f\" - {bucket['Name']}\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"S3 connection error: {e}\")\n",
    "\n",
    "    def process_all_tickets(self) -> None:\n",
    "        \"\"\"Process all loaded support tickets.\"\"\"\n",
    "        success_count = 0\n",
    "        fail_count = 0\n",
    "\n",
    "        for ticket in self.support_tickets:\n",
    "            if self.insert_ticket(ticket):\n",
    "                success_count += 1\n",
    "            else:\n",
    "                fail_count += 1\n",
    "                self.logger.error(f\"Failed to process ticket {ticket['ticket_id']}\")\n",
    "\n",
    "        self.logger.info(\n",
    "            f\"Processed {success_count} tickets successfully, {fail_count} failed\"\n",
    "        )\n",
    "\n",
    "    def run(self, tickets_file: Optional[str] = None) -> None:\n",
    "        \"\"\"\n",
    "        Run the full process of setting up and processing tickets.\n",
    "\n",
    "        Args:\n",
    "            tickets_file: Optional path to a JSON file with ticket data\n",
    "        \"\"\"\n",
    "        self.test_connections()\n",
    "        self.has_vector_support = self.setup_database()\n",
    "        self.load_tickets(tickets_file)\n",
    "        self.upload_images()\n",
    "        self.process_all_tickets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59c1d091",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 15:38:29,412 - __main__ - INFO - Testing Database Connection\n",
      "2025-06-10 15:38:29,434 - __main__ - INFO - Connected to PostgreSQL: PostgreSQL 17.4 (Debian 17.4-1.pgdg120+2) on aarch64-unknown-linux-gnu, compiled by gcc (Debian 12.2.0-14) 12.2.0, 64-bit\n",
      "2025-06-10 15:38:29,444 - __main__ - INFO - pgvector is available: ('vector', None)\n",
      "2025-06-10 15:38:29,445 - __main__ - INFO - pgvector is available but not installed yet\n",
      "2025-06-10 15:38:29,445 - __main__ - INFO - Testing S3 Connection\n",
      "2025-06-10 15:38:29,461 - __main__ - INFO - Connected to S3, found 1 buckets\n",
      "2025-06-10 15:38:29,461 - __main__ - INFO -  - xyz-support-images\n",
      "2025-06-10 15:38:29,497 - __main__ - INFO - pgvector extension enabled successfully\n",
      "2025-06-10 15:38:29,503 - __main__ - INFO - Table with vector column created successfully\n",
      "2025-06-10 15:38:29,504 - __main__ - INFO - Loaded 2 tickets from ./data/vector_ticket_data.json\n",
      "2025-06-10 15:38:29,516 - __main__ - INFO - Bucket xyz-support-images already exists\n",
      "2025-06-10 15:38:29,569 - __main__ - INFO - Uploaded image to s3://xyz-support-images/tickets/XYZ-2001/image.png\n",
      "2025-06-10 15:38:29,624 - __main__ - INFO - Uploaded image to s3://xyz-support-images/tickets/XYZ-2002/image.png\n",
      "2025-06-10 15:38:30,449 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-06-10 15:38:30,497 - __main__ - INFO - Ticket XYZ-2001 inserted successfully\n",
      "2025-06-10 15:38:30,995 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-06-10 15:38:31,000 - __main__ - INFO - Ticket XYZ-2002 inserted successfully\n",
      "2025-06-10 15:38:31,000 - __main__ - INFO - Processed 2 tickets successfully, 0 failed\n"
     ]
    }
   ],
   "source": [
    "system = DataProcess()\n",
    "system.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
